{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRg-QBFjVNGb"
   },
   "source": [
    "# Binary Classification with K-Nearest Neighbour\n",
    "\n",
    "Today we are going to be looking at a breast-cancer dataset  and use the KNN algorithm to classify tumors as either malignant or beniign. \n",
    "\n",
    "The dataset is historical and anonymized patient data from the US, which contains information on 10 different attributes of patient tumors \n",
    "\n",
    "Before we get started we will need to import some libraires:\n",
    "\n",
    "1. Numpy - Fundamental package for scientific computing with Python\n",
    "2. Matplotlib -  Python 2D plotting library \n",
    "3. Pandas - Library providing high-performance, easy-to-use data structures and data analysis tools.\n",
    "4. SKLearn - Simple and efficient tools for data mining and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDuRCNUvWL10"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, metrics#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWv-qVl601nn"
   },
   "source": [
    "## Load Dataset\n",
    "First of all we want to read the CSV file that contains the dataset we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sn2QZLY4g65-"
   },
   "outputs": [],
   "source": [
    "# Load the tabular data into the notebook\n",
    "raw_data = load_breast_cancer()\n",
    "data = pd.DataFrame(raw_data.data)\n",
    "data = pd.concat([data, pd.Series(raw_data.target)], axis=1)\n",
    "column_names = np.append(raw_data.feature_names, 'diagnosis')\n",
    "data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ra_yk2_shvs5"
   },
   "outputs": [],
   "source": [
    "# Now let's view the first 10 rows in the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfS0u22f8uaN"
   },
   "source": [
    "## Manipulating the Data\n",
    "\n",
    "Pandas Dataframe has the indexer *iloc* that is used to select rows and columns by number.\n",
    "\n",
    "The syntax is `data.iloc[<row_selection>][<column_selection>]`\n",
    "\n",
    "Below are some examples for using iloc to refesh the topic.\n",
    "\n",
    "ToDo:\n",
    "- Use iloc to separate the X and Y values of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMNA8_-t8X3c"
   },
   "outputs": [],
   "source": [
    "# Examples:\n",
    "data.iloc[0] # first row of data frame\n",
    "data.iloc[-1] # last row of data frame\n",
    "data.iloc[:5] # first 5 rows of data frame\n",
    "\n",
    "data.iloc[:, 0] # first column of data frame (id-number)\n",
    "data.iloc[:, -1] # last column of data frame (diagnosis)\n",
    "data.iloc[:, :5] # first 5 columns of data frame (id-number -> marginal_adhesion\n",
    "\n",
    "data.iloc[:5, :5] # first 5 rows, first 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4T3SG_99sTbZ"
   },
   "outputs": [],
   "source": [
    "# Now we use iloc to separate the X and Y values of our dataset\n",
    "\n",
    "# X values are the columns 1->31 (Remember selection is UP TO column 31 not INCLUDING)\n",
    "# Y values are in column 31\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0gJ7DJx8m7U"
   },
   "source": [
    "## Split the Data\n",
    "We need to split the dataset into training and validation data. The training set is much larger than the test set as the model will achieve a higher accuracy with more data to look at. Validation only needs to be a smaller percentage of the overall set as we just need to see if the model is predicting correctly.\n",
    "\n",
    "Use the SKLearns train_test_split method that we have used in the last tutorial  to split up the data.\n",
    "\n",
    "ToDo:\n",
    "- Split the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlZo1xg1rAHa"
   },
   "outputs": [],
   "source": [
    "#Split the dataset into the Training set and Test set using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXrCYQQyB3-d"
   },
   "source": [
    "## Define and fit the model\n",
    "We now need to create the classifier that we will use and train it with our data. \n",
    "\n",
    "To Do:\n",
    "- Define the model (KNeighborsClassifier)\n",
    "- Fit the model\n",
    "- Predict the diagnosis values for the test data given\n",
    "- Find out how accurate our model was "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZ4xgnf5tJYH"
   },
   "outputs": [],
   "source": [
    "# Create our classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "\n",
    "# Fit a model using the classifier and our training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnQDCUtWYMpj"
   },
   "outputs": [],
   "source": [
    "# Predict the diagnosis values on the test dataset and print the predictions\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11P3jqY2QQPg"
   },
   "source": [
    "## Analysis of Model Performance\n",
    "Now we have our model we need to look how well it performed. A good fitting model is one where the difference between the actual values and the predicted values is small and unbiased for train, validation and test data sets. \n",
    "\n",
    "### Confusion Matrix\n",
    "A confusion matrix is a table that is used to describe how well a classification model performs on a set of labelled test data. An example confusion matrix for a binary classifier is:\n",
    "\n",
    "![](https://miro.medium.com/max/712/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n",
    "\n",
    "- True positivies (TP) - actual positives that are correctly identified as positive\n",
    "- True negatives (TN) - actual negatives that are correctly identified as negative\n",
    "- False positives (FP) -  actual negatives that are incorrectly identified as positive\n",
    "- False negatives (FN) - actual positives that are incorrectly identified as negative\n",
    "\n",
    "### Scores\n",
    "From a confusion matrix, there are many different scores that can be computed to analyse the classifier's performance. The most important are:\n",
    "\n",
    "**Accuracy** - the ratio of correctly predicted examples to the total examples  \\\n",
    "\\begin{equation*}\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "**Precision** - the ratio of correct positive predictions to the total predicted positives. For example, if a breast cancer screening comes back *positive*, how likely are you to *actually* have breast cancer?\n",
    "\n",
    "\\begin{equation*}\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "\\end{equation*}\n",
    "\n",
    "**Recall** -  the ratio of correct positive predictions to the total positive examples. For example, if a breast cancer screening comes back *negative*, how likely are you to *actually* have breast cancer that has been missed?\n",
    "\n",
    "\\begin{equation*}\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "In some situations precision might be more important than recall or vice versa. If both are important then we can use F1 score.\n",
    "\n",
    "**F1 score** - used when we need a balance between precision and recall\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 = 2*\\frac{precision*recall}{precision+recall}=  2*\\frac{TP}{TP + FP + FN}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3721,
     "status": "ok",
     "timestamp": 1563532319237,
     "user": {
      "displayName": "Llinos Williams",
      "photoUrl": "https://lh4.googleusercontent.com/-igShd0Prym8/AAAAAAAAAAI/AAAAAAAAink/AvwRnInjI_Q/s64/photo.jpg",
      "userId": "02920130278902993455"
     },
     "user_tz": -60
    },
    "id": "b_GRTipRDuVe",
    "outputId": "55c1f1b3-ea45-4b5a-ed50-03017053aae9"
   },
   "outputs": [],
   "source": [
    "# Now we have our model and predictions, we need to look at how accurate it was\n",
    "# SciKit learn actually comes with built in functions for evaluating models \n",
    "\n",
    "print(\"Accuracy:\\n%s\" % metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Note support = the number of occurrences of each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyJHeHRxEMiB"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Experiment with the train/test ratio to see how it changes how well the model performs. \n",
    "    What's the highest and lowest accuracies you can achieve? How did you achieve this? Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6mLiYerzdl-"
   },
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n",
    "\n",
    "#bias/variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FvWGAYuPub7"
   },
   "source": [
    "2. Using the equations above, manually calculate the accuracy, precision, recall and F1 measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2YUoOASzeGm"
   },
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Binary_classification_KNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
